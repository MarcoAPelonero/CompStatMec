import matplotlib.pyplot as plt
import numpy as np
import subprocess
import os
from scipy.optimize import curve_fit

global TIME 
TIME = 1

def runSimulation(numParticles, density, timeStep, numSteps, filename, simIndex):
    """
    Runs the simulation with the given parameters.
    """
    try:
        print(f"Running simulation {simIndex}...")
        print(f"Parameters: {numParticles} particles, density {density}, time step {timeStep}, {numSteps} steps.")
        subprocess.run(["./build/main.exe", str(numParticles), str(density), str(timeStep), str(numSteps), filename], check=True)
        print("Simulation complete.")
    except Exception as e:
        print(f"Error running simulation: {e}")
        raise

def readEnsembleData(filename):
    """
    Reads the ensemble data file generated by the simulation.
    The file contains multiple snapshots separated by blank lines.
    The first line should be a header: x y z vx vy vz energy.
    """
    print(f"Opening file: {filename}")
    try:
        with open(filename, 'r') as f:
            # Read the file content
            content = f.read().strip()

        # Split into lines
        lines = content.split('\n')

        # Extract the header
        header = lines[0].strip().split()
        print(f"Header: {header}")

        data_lines = lines[1:]
        # Split snapshots by blank lines
        snapshot_blocks = []
        current_block = []
        for line in data_lines:
            line = line.strip()
            if line == '' and current_block:
                snapshot_blocks.append(current_block)
                current_block = []
            elif line != '':
                current_block.append(line)
        # Add the last block if not empty
        if current_block:
            snapshot_blocks.append(current_block)

        # Parse each snapshot into numerical data
        raw_data = []
        for block in snapshot_blocks:
            snapshot_data = [list(map(float, l.split())) for l in block]
            raw_data.append(snapshot_data)

        data_reshaped = np.array(raw_data)
        print(f"Data shape: {data_reshaped.shape}")

    except Exception as e:
        print(f"Error reading file: {e}")
        raise

    return header, data_reshaped

def computeOrder(minDelta, maxDelta, numSimulations, numParticles=100, density=0.5, numSteps=1000, skipSnapShots=0):
    deltaTime = np.linspace(minDelta, maxDelta, numSimulations)
    errors = []
    skips = [1000, 100, 10, 10, 10]  # Adjust if needed
    for i, dt in enumerate(deltaTime):
        filename = f"data/ensemble_{i+1}.dat"
        steps = int(TIME / dt)
        print(f"Steps for simulation {i+1}: {steps}")
        runSimulation(numParticles, density, dt, steps, filename, i+1)
        header, data = readEnsembleData(filename)

        # Extract the energy column index from the header
        energy_index = header.index('energy')

        # Ensure enough snapshots to skip the desired number
        if data.shape[0] <= skipSnapShots:
            print("Not enough snapshots to skip the desired number. Consider increasing the number of steps.")
            continue

        # Use only data after skipSnapShots for analysis
        polished_data = data[skipSnapShots:]

        # Compute total energy for each snapshot
        total_energies = np.sum(polished_data[:, :, energy_index], axis=1)

        # Automatically detect stabilization point
        # Stabilization happens when energy variations settle below a threshold
        stabilization_index = next(
            (i for i in range(1, len(total_energies)) 
             if np.abs(total_energies[i] - total_energies[i-1]) < 10),
            None
        )

        if stabilization_index is None:
            print(f"Simulation {i+1}: Unable to detect stabilization point.")
            continue

        stabilized_energies = total_energies[stabilization_index:]
        plt.plot(stabilized_energies)
        plt.show()
        initial_energy = stabilized_energies[0]

        # Compute energy errors during the stabilized period
        energy_errors = np.abs(stabilized_energies - initial_energy)
        average_error = np.mean(energy_errors)
        errors.append((dt, average_error))
        print(f"Timestep: {dt}, Average Energy Error (stabilized period): {average_error}")

    # Analyze scaling behavior
    if errors:
        dts, errs = zip(*errors)

        # Fit a quadratic curve
        def quadratic_fit(dt, C):
            return C * dt**2

        popt, _ = curve_fit(quadratic_fit, dts, errs)

        # Plot the results
        plt.figure()
        plt.plot(dts, errs, 'bo', label='Energy error')
        plt.plot(dts, quadratic_fit(np.array(dts), *popt), 'r-', label='Quadratic fit')
        plt.xlabel('Timestep (\u0394t)')
        plt.ylabel('Average Energy Error')
        plt.legend()
        plt.show()

    return errors

if __name__ == "__main__":
    if not os.path.exists("data"):
        os.system("mkdir data")

    numParticles = 20
    density = 0.5
    numSteps = 10000
    minDelta = 0.0001
    maxDelta = 0.01
    numSimulations = 5
    skipSnapShots = 0

    errors = computeOrder(minDelta, maxDelta, numSimulations, numParticles, density, numSteps, skipSnapShots)
